## 설치 방법

#### python 설치
- 파이썬 3.11 버전 설치
pyenv install 3.11

- 3.11 버전의 python 설정
pyenv global 3.11

-파이썬 버전 확인
python --version

#### Poetry 설치
- 아래의 명령어를 실행하여 Poetry 패키지 관리 도구를 설치
pip3 install poetry==1.8.5

-파이썬 가상환경 설정
poetry shell

-파이썬 패키지 일괄 업데이트
poetry update

#### 참고
.env 파일에 개인에 맞는 API KEY 입력


[2주차] 과제
질문 1:기존 RAG방식의 한계
질문 2:RAG의 장점
질문 3:monoT5와 RankLLaMA 중 성능이 더 좋은 것은?

-청킹 방법별 차이점 분석
1.RecursiveCharacterTextSplitter:
-문자/구분자 기준으로 문자수를 chunk_size(문자 개수)로 자름

2.TokenTextSplitter:
-토크나이저를 통해 토큰으로 만든 뒤 chunk_size(토큰 개수)로 자름
-문자 기준 splitter를 쓰면 1000자가 400토큰일수도 1600토큰일수도 있음
-토큰 크기를 제어해야할 때 사용

**ex** "고양이가 공을 굴린다. 강아지가 짖는다." 

토크나이저로 토큰화
-> [ "고양", "이", "가", "공", "을",
  "굴", "린", "다", ".", 
  "강아지", "가", "짖", "는", "다", "." ]

5토큰 단위로 청킹
->청크 1 :["고양", "이", "가", "공", "을"]
->청크 2 :["굴", "린", "다", ".", "강아지"]
->청크 3 :["가", "짖", "는", "다", "."]

이후 각 청크에 대해 임베딩

-검색 결과 품질 비교
# 1번 질문
## 1.RecursiveCharacterTextSplitter
---- Result 2 ----
신 연구 동향인 Advanced RAG까지 다루고 있다.
2.1. RAG 모델의 개요
RAG 모델은 질문에 대한 답변을 생성하기 위해 검색
과 생성이라는 두 가지 과정을 결합한 모델이다(Lewis et 
al., 2020). 마치 사람이 궁금한 것을 해결하기 위해 책이
나 인터넷을 검색하고, 찾은 정보를 바탕으로 답변을 구
성하는 것과 비슷하다. 이 모델은 질문에 대한 답변을 생
성하기 위해 먼저 관련 문서를 검색하고, 이를 바탕으로 
답변을 생성한다. 이 과정은 질문에 대한 정확한 답변을 
생성하는 데 도움이 된다. RAG 모델은 다양한 질문 유형
에 대응할 수 있으며, 특정 도메인에 대한 지식이 부족할 
경우에도 효과적으로 답변을 생성할 수 있다. 따라서 기
존 생성 모델에 비해 정보의 정확성과 일관성을 높일 수 
있다는 장점을 가지고 있다
.
RAG 모델은 아래와 같이 두 단계로 구성된다.
• 검색 단계: 주어진 질문과 관련된 정보를 지식에서 
검색 엔진을 통해 검색한다.
• 생성 단계: 검색된 정보를 기반으로 답변을 생성한다. 
2.1.1. RAG 모델 구현 흐름
RAG 모델은 텍스트 생성 작업을 수행하는 모델로 주
어진 소스 데이터로부터 정보를 검색하고, 해당 정보를 
활용하여 원하는 텍스트를 생성하는 과정을 수행한다(정
천수, 2023d). RAG 사용을 위한 데이터처리 과정은 원본 
데이터를 청크(Chunk)단위의 작은 조각으로 나누고 텍스
트 데이터를 숫자인 벡터로 전환하는 임베딩(Embedding)

---- Result 3 ----
가 86%까지 올라가는 경우도 확인되었다(Angels et al., 
2024). 이렇게 RAG 모델은 내부 지식 검색과 생성을 결
합하여 더욱 정확한 답변을 생성하는 데 효과적인 모델
로 알려져 있다

## 2.TokenTextSplitter
---- Result 1 ----
정천수
102 지식경영연구 제25권 제3호
을 거처 벡터 저장소에 저장된다(Microsoft, 2023). 이러
한 RAG모델 기반 생성형 AI 서비스 구현 흐름은 <그림 
1>과 같다(정천수, 2023d).
2.1.2. RAG기반 Vector Store 유형
RAG시스템을 구축하기 위해서는 지식이 저장되는 벡
터 데이터베이스를 사용하게 되는데, 벡터 데이터베이스
에 대한 일반적인 벡터 파이프라인은 인덱싱(Indexing), 
조회(Querying), 사후처리(Post Processing)와 같은 3단계
를 거친다(Devtorium, 2023). 특히, RAG기반 벡터 저장소
(Vector Store) 저장 유형은 <그림 2>와 같이 모든 소스 
데이터를 사전에 Vector Store에 저장하는 경우와 질문 
시 실시간으로 넣는 경우로 나눌 수 있다(정천수, 2023d).
기업에서는 내부 지식을 Open LLM을 통해 서비스하
게 되었을 때 보안 이슈 때문에 Local LLM을 사용하는 
것이 중요한 이슈이다(정천수, 2023d). 이때 각 구간별로 
가장 잘 처리할 수 있는 Local LLM을 여러 개 구성하여 
사용하는 것이 효과적인데, <그림 2>에서 여러 개의 소
<그림 1> RAG기반 생성형 AI 서비스 구현 흐름
<그림 2> RAG기반 Vector Store 구성 유형 및 처리절차

---- Result 2 ----
정천수
104 지식경영연구 제25권 제3호
LangChain 또는 LlamaIndex 프레임워크는 이러한 전략
을 구현할 수 있도록 각 항목별 라이브러리를 제공하고 
있어 구현을 좀더 쉽게 할 수 있도록 하고 있다
.
2.2.2. Advanced RAG 유형 연구 및 개선 방향
현재 연구되고 있는 대표적인 Advanced RAG 방안을 
살펴보고, 각 유형의 강점과 약점을 분석하여 본 연구의 
방향성을 제시하고자 한다. 
• Self-RAG: 이 방식은 생성된 답변을 다시 검색하여 
관련 정보를 찾고, 이를 기반으로 답변을 개선하는 
방법이다. 이를 통해 답변의 정확도와 유창성을 향
상시킬 수 있다(Asai et al., 2023). 그러나 이 접근법
은 검색된 정보의 품질에 크게 의존하며, 정보의 신
뢰성을 평가하는 메커니즘이 부족하다는 단점이 있
다
. 또한, 반복적인 검색과 생성 과정에서 많은 리소
스가 소모되므로, 이를 보완하기 위해 초기 검색 단
계에서 더 정교한 필터링을 통해 검색 범위를 줄이
고
, 반복적인 처리를 최소화하는 최적화 기법이 필
요하다.
• Corrective RAG: 이 방식은 생성된 답변의 오류를 
수정하기 위해 Corrective Agent를 사용하는 방법이
다. Corrective Agent는 답변의 오류를 식별하고, 이
를 수정하기 위한 정보를 검색한다. 이를 통해 답변
의 신뢰성을 높일 수 있다(Yan et al., 2024). 그러나 
초기 검색 결과가 부정확할 경우 이를 수정하는 과
정이 명확하게 정의되지 않아
, 추가적인 처리 시간
이 필요하게 되며, 실제 적용 시 비효율성을 초래할 
수 있다. 이를 보완하기 위해, 수정 프로세스를 구체
화하고, 사전 검토 단계에서 잠재적인 오류를 미리 
감지하여 이를 기반으로 답변을 생성하도록 유도하
는 기법을 도입하면
, 보다 효과적인 정보 검색 및 응
답 생성이 가능해질 것이다.
• Adaptive RAG: 이 방식은 질문의 유형에 따라 적절
한 RAG 방식을 선택하여 적용하는 방법이다. 예를 
들어, 사실적 질문에는 Self-RAG 방식을, 의견 질문
에는 Corrective RAG 방식을 사용하는 등 질문 유형
에 따라 최적의 방식을 선택함으로써 답변의 정확도
를 높일 수 있다
(Jeong et al., 2024). 그러나 현재 연
구에서는 피드백 루프의 설계와 구현에 대한 구체적
인 사례가 부족하다는 한계가 있다
. 이를 개선하기 
위해서는 질문 유형을 정확히 분류하는 것이 핵심 
과제로
, 분류의 정밀도를 높이기 위해 추가적인 학
습 데이터를 활용하거나, 특정 도메인에 맞춘 분류 
기법을 도입하는 방법을 고려할 수 있다.
본 연구에서는 LangGraph와 같은 그래프 기반 기술 
및 에이전트를 활용하여, 검색된 정보의 신뢰성을 효과
적으로 평가하고, 사전에 잠재적인 오류를 미리 감지함
으로써 응답 품질을 개선할 수 있는 방법을 제시하고자 
한다
.
3. Advanced RAG 모델의 설계
본 장에서는 기존 연구에서 제안된 다양한 Advanced 
RAG 방안들을 검토하고, 이를 기반으로 향상된 RAG 시스
템을 설계한다. 특히, Self-RAG, Corrective RAG, Adaptive 
RAG 등의 방안들을 면밀히 분석하고, 이를 통해 얻은 개
선점을 바탕으로 <그림 3>과 같이 구현 모델을 제시 한
다. Agent RAG 시스템에 대한 구현은 Corrective RAG을 
기본으로 하고 Self-RAG, Adaptive RAG를 참조하고 있다. 
일반적인 RAG 시스템을 향상시키기 위한 워크플로는 
기존처럼 벡터 데이터베이스에서 문서 청크를 검색한 다
음 
LLM을 사용하여 검색된 각 문서 청크가 입력 질문과

---- Result 3 ----
 등 다양한 분야에 AI 시
스템을 도입하고 있다. 하지만 이러한 시스템은 데이터 
편향, 환각 문제, 실시간 데이터 처리의 어려움, 특정 분
야에 대한 지식 부족 등의 한계를 가지고 있다. 특히, 사
용자의 질문에 시스템이 답변을 찾지 못할 때 ‘죄송합니
다, 모르겠습니다’라고 명확하게 답변하지 못하고, 관련 
없는 정보를 마치 사실인 것처럼 답변을 제시하는 환각
(Hallucination) 이 발생한다. 또한, 정확한 답변이 존재하
지만 검색 결과의 순위가 낮아 답변에서 누락되는 경우
도 발생한다
. 특히, 기업의 사례를 보면, 금융 회사의 경
우 과거 데이터로 인한 잘못된 예측으로 손실을 입고, 전
자 상거래 기업은 실시간으로 재고 현황이나 배송 상태
와 같은 정보를 반영하지 못해 고객 만족도가 크게 하락
하는 문제가 발생한다
. 또한 제조업체는 기술 지원을 위
한 RAG 기반 시스템을 도입했으나, 시스템이 복잡한 기
술 용어와 전문 지식을 제대로 이해하지 못해 고객들이 
잘못된 정보를 제공받는 사례가 발생하게 된다
(Scott et 
al., 2024; 정천수, 2024).
이렇게 RAG모델의 효과는 고품질의 데이터베이스에 
크게 의존하고 있기 때문에 데이터의 질이 모델 성능에 
직접적인 영향을 미친다
(김종철, 2024). 기존의 RAG 모
델은 한 번에 지식을 적재한 후, 재작업 없이 답변을 생
성함으로 정확도 저하 문제와 RAG구성 시점 이후의 실
시간 데이터를 볼 수 없다. 이렇게 처음에 한번 벡터화한

---- Result 4 ----
지식 기반 QA개선을 위한 Advanced RAG 시스템 구현 방법
Knowledge Management Research. Sep. 2024 101
지식정보를 한 번의 답변 생성 과정을 거치기 때문에, 답
변이 부정확할 경우에 지식정보를 새로운 정보로 재 작
업하는 과정 없이 답변을 제공하여 답변의 정확도가 저
하되는 경우가 발생될 수가 있다
. 특히 복잡한 질문에 대
한 답변을 생성할 때 이러한 문제가 생길 수 있으며, 기
존 RAG 모델은 다양한 질문 유형에 효과적으로 대응하
기 어려운 측면이 있었다. 잘못된 검색 전략으로 인해 관
련 없는 문서가 질문에 답변하는 데 사용될 수 있고, 여
전히 LLM에서 나타나는 환각을 겪거나 질문에 대답하
지 못하는 경우가 발생되는 한계점을 가지고 있다(전준
영 등, 2024)
본 연구는 이러한 전통적인 QA 시스템에서 발생하는 
정보 검색 및 환각 문제를 해결하기 위한 새로운 접근 
방식을 제안하고자 한다
. 특히, 실시간 데이터 접근과 문
서 검증 프로세스를 통합하여 질문에 대한 정확한 답변
을 제공할 수 있도록 하는 것을 목표로 한다
. 실시간 데
이터에 접근하고, 검색된 문서가 실제로 질문에 응답하
는 데 관련이 있는지 확인한다. 이를 통해 RAG 시스템은 
최근 이벤트와 실시간 데이터에 대한 질문에 답할 수 있
고 환각에 덜 취약하게 향상된 
RAG 시스템을 구현함으
로써 생성형 AI 서비스의 품질 및 성능을 향상시키는 데 
기여할 것이다. 
본 논문의 서론에서는 연구의 배경과 목적, 기존 RAG 
모델의 한계, 연구의 중요성 및 기여도, 논문의 구조에 
대해 설명한다. 이론적 배경에서는 RAG 모델의 개요와 
Advanced RAG 방안, 기존 연구 개선 유형 사례를 검토
하고, Advanced RAG 모델의 설계에서는 Advanced RAG
의 구성 흐름과 Agent RAG 구성, 기타 향상된 기능에 
대해 다룬다. 시스템 구현에서는 LangGraph의 개요 및 
적용 방법, 시스템 구현 과정 및 결과를 기술하고, 테스
트에서는 구현된 코드의 개선된 결과값을 제시하고 있
다
. 마지막으로 결론에서는 연구 결과의 요약, 연구의 한
계 및 향후 연구 방향에 대해 다루고 있다. 
2. 이론적 배경
본 연구를 위해 RAG 모델과 관련된 자료에 대하여 최
근 발표된 주요 연구 논문, 저널 기사 등을 면밀히 분석
하고 조사하였다. 본 장에서는 RAG 모델의 개념부터 최
신 연구 동향인 Advanced RAG까지 다루고 있다.
2.1. RAG 모델의 개요
RAG 모델은 질문에 대한 답변을 생성하기 위해 검색
과 생성이라는 두 가지 과정을 결합한 모델이다(Lewis et 
al., 2020). 마치 사람이 궁금한 것을 해결하기 위해 책이
나 인터넷을 검색하고, 찾은 정보를 바탕으로 답변을 구
성하는 것과 비슷하다. 이 모델은 질문에 대한 답변을 생
성하기 위해 먼저 관련 문서를 검색하고, 이를 바탕으로 
답변을 생성한다. 이 과정은 질문에 대한 정확한 답변을 
생성하는 데 도움이 된다. RAG 모델은 다양한 질문 유형
에 대응할 수 있으며, 특정 도메인에 대한 지식이 부족할 
경우에도 효과적으로 답변을 생성할 수 있다. 따라서 기
존 생성 모델에 비해 정보의 정확성과 일관성을 높일 수 
있다는 장점을 가지고 있다
.
RAG 모델은 아래와 같이 두 단계로 구성된다.
• 검색 단계: 주어진 질문과 관련된 정보를 지식에서 
검색 엔진을 통해 검색한다.
• 생성 단계: 검색된 정보를 기반으로 답변을 생성한다. 
2.1.1. RAG 모델 구현 흐름
RAG 모델은 텍스트 생성 작업을 수행하는 모델로 주
어진 소스 데이터로부터 정보를 검색하고, 해당 정보를 
활용하여 원하는 텍스트를 생성하는 과정을 수행한다(정
천수, 2023d). RAG 사용을 위한 데이터처리 과정은 원본 
데이터를 청크(Chunk)단위의 작은 조각으로 나누고 텍스
트 데이터를 숫자인 벡터로 전환하는

# 2번 질문
## 1.RecursiveCharacterTextSplitter
하지만 이러한 시스템은 데이터 
편향, 환각 문제, 실시간 데이터 처리의 어려움, 특정 분
야에 대한 지식 부족 등의 한계를 가지고 있다. 특히, 사
용자의 질문에 시스템이 답변을 찾지 못할 때 ‘죄송합니
다, 모르겠습니다’라고 명확하게 답변하지 못하고, 관련 
없는 정보를 마치 사실인 것처럼 답변을 제시하는 환각
(Hallucination) 이 발생한다. 또한, 정확한 답변이 존재하
지만 검색 결과의 순위가 낮아 답변에서 누락되는 경우
도 발생한다
. 특히, 기업의 사례를 보면, 금융 회사의 경
우 과거 데이터로 인한 잘못된 예측으로 손실을 입고, 전
자 상거래 기업은 실시간으로 재고 현황이나 배송 상태
와 같은 정보를 반영하지 못해 고객 만족도가 크게 하락
하는 문제가 발생한다
. 또한 제조업체는 기술 지원을 위
한 RAG 기반 시스템을 도입했으나, 시스템이 복잡한 기
술 용어와 전문 지식을 제대로 이해하지 못해 고객들이 
잘못된 정보를 제공받는 사례가 발생하게 된다
(Scott et 
al., 2024; 정천수, 2024).
이렇게 RAG모델의 효과는 고품질의 데이터베이스에 
크게 의존하고 있기 때문에 데이터의 질이 모델 성능에 
직접적인 영향을 미친다
(김종철, 2024). 기존의 RAG 모
델은 한 번에 지식을 적재한 후, 재작업 없이 답변을 생
성함으로 정확도 저하 문제와 RAG구성 시점 이후의 실
시간 데이터를 볼 수 없다. 이렇게 처음에 한번 벡터화한
# 3번 질문
## 1.RecursiveCharacterTextSplitter
at a computational cost of 11.71 seconds per
query. In practice, the "Hybrid" or "Original"
methods are recommended, as they maintain
comparable performance with reduced latency.
• Reranking Module: Reranking is critical to
maintaining high-quality results, as demonstrated
by a performance drop in its absence. Among
DLM-based rerankers,**** monoT5 significantly out-
performed monoBERT and RankLLaMA. ****This
superiority can be attributed to monoT5’s larger
parameter set and more extensive training data, as
well as its encoder-decoder architecture, which
provides enhanced natural language understand-
ing compared to the decoder-only LLaMA model.
MonoT5’s effectiveness in boosting the relevance
of retrieved documents affirms the necessity of
reranking in improving the quality of generated
responses.
• Repacking Module: The Reverse configuration
exhibited superior performance, achieving an
RAG score of 0.560. This highlights the impor-
tance of positioning more relevant context closer
to the query to yield optimal results.
• Summarization Module: The Recomp extrac-
tive summarization method demonstrated supe-
rior performance over LongLLMLingua, an ab-
17722

큰 차이는 아니지만 대체적으로 TokenTextSplitter 나은 품질을 출력함

-어려웠던 점과 해결 과정
1.TokenTextSplitter와 다른 스플리터들의 chunk_size의 차이 : 토큰 기준 /문자 수 기준
2.TokenTextSplitter의 청킹 -> 임베딩 과정